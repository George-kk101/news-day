#!/usr/bin/env python
# vim:fileencoding=utf-8
import os
import time

from calibre.web.feeds.news import BasicNewsRecipe

class PeoplesDailyFixed(BasicNewsRecipe):
    title = '人民日报 (修复完善版)'
    __author__ = 'ceapas, fixed by AI'
    description = '每日精选人民日报各频道最新资讯，带实体报纸头版封面'
    language = 'zh'
    category = 'News, China'
    publisher = 'people.com.cn'
    
    # 核心修复 1：修正编码为 UTF-8
    encoding = 'utf-8' 

    oldest_article = 1.5
    max_articles_per_feed = 30
    
    no_stylesheets = True
    remove_javascript = True
    use_embedded_content = False

    # 选项：允许在 Calibre 桌面版界面中调整抓取天数
    recipe_specific_options = {
        'days': {
            'short': '抓取多少天内的文章',
            'long': '例如填写 0.5 表示只抓取过去 12 小时的文章',
            'default': str(oldest_article)
        }
    }

    def __init__(self, *args, **kwargs):
        BasicNewsRecipe.__init__(self, *args, **kwargs)
        d = self.recipe_specific_options.get('days')
        if d and isinstance(d, str):
            self.oldest_article = float(d)

    # 核心修复 2：使用现代的 CSS class 选择器精准提取正文
    keep_only_tags = [
        dict(attrs={'class': ['rm_txt', 'layout rm_txt cf', 'text_c', 'box_con', 'd2txt_1', 'article']}),
        dict(id=['rwb_zw', 'p_content']),
    ]

    remove_tags = [
        dict(name=['script', 'noscript', 'style', 'iframe']),
        dict(attrs={'class': ['edit', 'page_down', 'share', 'author', 'rm_pl', 'channel cf']}),
        dict(id=['comments', 'commentArea', 'rwb_tjyd']),
    ]

    # 保留了原有的丰富栏目，去掉了失效的注释项
    feeds = [
        ('时政', 'http://www.people.com.cn/rss/politics.xml'),
        ('国际', 'http://www.people.com.cn/rss/world.xml'),
        ('经济', 'http://www.people.com.cn/rss/finance.xml'),
        ('体育', 'http://www.people.com.cn/rss/sports.xml'),
        ('教育', 'http://www.people.com.cn/rss/edu.xml'),
        ('文化', 'http://www.people.com.cn/rss/culture.xml'),
        ('社会', 'http://www.people.com.cn/rss/society.xml'),
        ('传媒', 'http://www.people.com.cn/rss/media.xml'),
        ('娱乐', 'http://www.people.com.cn/rss/ent.xml'),
        ('海峡两岸', 'http://www.people.com.cn/rss/haixia.xml'),
        ('生活提示', 'http://www.people.com.cn/rss/life.xml'),
        ('卫生', 'http://www.people.com.cn/rss/medicine.xml'),
    ]

    # 核心修复 3：保留并优化原作者的“每日实体报纸头版作封面”功能
    def get_cover_url(self):
        try:
            # 强制使用北京时间计算日期，防止 GitHub 海外服务器时区错误导致找不到封面
            os.environ['TZ'] = 'Asia/Shanghai'
            if hasattr(time, 'tzset'):
                time.tzset()
        except Exception:
            pass
            
        year = time.strftime('%Y')
        month = time.strftime('%m')
        day = time.strftime('%d')
        
        # 拼接当日《人民日报》数字报头版高清大图地址
        cover = f'http://paper.people.com.cn/rmrb/images/{year}-{month}/{day}/01/rmrb{year}{month}{day}01_b.jpg'
        
        br = BasicNewsRecipe.get_browser(self)
        try:
            response = br.open(cover)
            if response.code == 200:
                self.log('\n成功获取当日人民日报头版封面!')
                return cover
        except Exception:
            self.log('\n今日头版封面暂未更新或抓取失败: ' + cover)
        return None

    # 核心修复 4：剔除了原版早已失效的 append_page 翻页逻辑，换成现代的排版清理
    def preprocess_html(self, soup):
        # 删掉文章末尾多余的责编信息
        for p in soup.findAll('p'):
            if p.text and ('责编：' in p.text or '编辑：' in p.text):
                if len(p.text.strip()) < 30:
                    p.extract()
                    
        # 优化图片在 Kindle 上的显示（强制居中，取消固定宽高）
        for img in soup.findAll('img'):
            if img.has_attr('width'):
                del img['width']
            if img.has_attr('height'):
                del img['height']
            if not img.parent or img.parent.name != 'div':
                div = soup.new_tag('div', attrs={'style': 'text-align:center; margin: 1em 0;'})
                img.wrap(div)
                
        return soup